# GPT, ChatGPT, InstructGPT
![image](https://user-images.githubusercontent.com/129742046/236900096-c38791b3-498e-4abb-85b4-277924d4a3bd.png)



### 1. ChatGPT

- ChatGPT is a sibling model to InstructGPT, which is trained to follow an instruction in a prompt and provide a detailed response.
- fine-tuned using Supervised Learning + RLHF 
- **Dataset :** A massive corpus of text data, around 570GB of data sourced from books, wikipedia, research articles, webtexts, websites and other forms of content and writing on the net - Approximately 300 billion words were fed into the system.
- The model works on probability as a result of which it is able to predict the next word/prompt in a sentence.
- While training, if the model gets output wrong, the correct answer is fed back into the model thereby training it to the right responses and also helping it build on its knowledge bank.
